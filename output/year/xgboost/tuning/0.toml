program = 'bin/xgboost_.py'

[base_config]
seed = 0

    [base_config.data]
    path = 'data/year'
    y_policy = 'mean_std'

    [base_config.fit]
    early_stopping_rounds = 50
    verbose = false

    [base_config.model]
    booster = 'gbtree'
    n_estimators = 2000
    n_jobs = -1
    tree_method = 'gpu_hist'

[optimization.options]
n_trials = 100

[optimization.sampler]
seed = 0

[optimization.space.model]
alpha = [ '?loguniform', 0, 1e-08, 100.0 ]
colsample_bylevel = [ 'uniform', 0.5, 1.0 ]
colsample_bytree = [ 'uniform', 0.5, 1.0 ]
gamma = [ '?loguniform', 0, 1e-08, 100.0 ]
lambda = [ '?loguniform', 0, 1e-08, 100.0 ]
learning_rate = [ 'loguniform', 1e-05, 1 ]
max_depth = [ 'int', 6, 10 ]
min_child_weight = [ 'loguniform', 1e-08, 100000.0 ]
subsample = [ 'uniform', 0.5, 1.0 ]
