{
    "config": {
        "data": {
            "cat_policy": "ohe",
            "path": "data/adult"
        },
        "fit": {
            "early_stopping_rounds": 1999,
            "verbose": true
        },
        "model": {
            "booster": "gbtree",
            "n_estimators": 2000,
            "n_jobs": -1,
            "tree_method": "gpu_hist"
        },
        "seed": 1
    },
    "environment": {
        "devices": {
            "CUDA_VISIBLE_DEVICES": "0",
            "torch.version.cuda": "10.1",
            "torch.backends.cudnn.version()": 7603,
            "torch.cuda.nccl.version()": 2708,
            "driver": "450.80.02",
            "0": {
                "name": "Tesla V100-PCIE-32GB",
                "total_memory": 34089730048
            }
        }
    },
    "dataset": "adult",
    "algorithm": "xgboost_",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9111508358295487,
                "recall": 0.9536788874841973,
                "f1-score": 0.9319299285943715,
                "support": 19775
            },
            "1": {
                "precision": 0.8287850467289719,
                "recall": 0.7068388330942132,
                "f1-score": 0.7629699733287447,
                "support": 6273
            },
            "accuracy": 0.8942337223587223,
            "macro avg": {
                "precision": 0.8699679412792602,
                "recall": 0.8302588602892053,
                "f1-score": 0.8474499509615581,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8913151250253443,
                "recall": 0.8942337223587223,
                "f1-score": 0.8912402096377808,
                "support": 26048
            },
            "roc_auc": 0.9525156536461623,
            "score": 0.8942337223587223
        },
        "val": {
            "0": {
                "precision": 0.8935194035557255,
                "recall": 0.9451971688574318,
                "f1-score": 0.9186320754716982,
                "support": 4945
            },
            "1": {
                "precision": 0.7886115444617785,
                "recall": 0.6447704081632653,
                "f1-score": 0.7094736842105263,
                "support": 1568
            },
            "accuracy": 0.8728696453247351,
            "macro avg": {
                "precision": 0.841065474008752,
                "recall": 0.7949837885103486,
                "f1-score": 0.8140528798411122,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8682629129892724,
                "recall": 0.8728696453247351,
                "f1-score": 0.868277345317005,
                "support": 6513
            },
            "roc_auc": 0.9258652576298465,
            "score": 0.8728696453247351
        },
        "test": {
            "0": {
                "precision": 0.8984806629834254,
                "recall": 0.9416164053075995,
                "f1-score": 0.9195429379196607,
                "support": 12435
            },
            "1": {
                "precision": 0.7765466297322253,
                "recall": 0.65600624024961,
                "f1-score": 0.7112050739957716,
                "support": 3846
            },
            "accuracy": 0.8741477796204165,
            "macro avg": {
                "precision": 0.8375136463578254,
                "recall": 0.7988113227786047,
                "f1-score": 0.8153740059577161,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8696766403875089,
                "recall": 0.8741477796204165,
                "f1-score": 0.870328060169444,
                "support": 16281
            },
            "roc_auc": 0.9264635281832665,
            "score": 0.8741477796204165
        }
    }
}
